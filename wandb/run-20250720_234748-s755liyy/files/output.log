/media/cc/2T/liouvilleViT/train_masked_blocks.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()  # Initialize GradScaler for mixed precision

--- Epoch 1/100 ---
Batch shape: torch.Size([1, 10000, 2, 50, 50])
/media/cc/2T/liouvilleViT/train_masked_blocks.py:128: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 2: Loss = 0.301704
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 3: Loss = 0.300618
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 4: Loss = 0.299457
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 5: Loss = 0.297926
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 6: Loss = 0.296564
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 7: Loss = 0.295358
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 8: Loss = 0.294086
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 9: Loss = 0.292756
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 10: Loss = 0.291625
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 11: Loss = 0.290355
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 12: Loss = 0.289080
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 13: Loss = 0.287838
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 14: Loss = 0.286643
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 15: Loss = 0.285297
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 16: Loss = 0.284005
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 17: Loss = 0.282995
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 18: Loss = 0.281709
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 19: Loss = 0.280155
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 20: Loss = 0.278933
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 21: Loss = 0.277894
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 22: Loss = 0.276294
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 23: Loss = 0.275135
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 24: Loss = 0.273781
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 25: Loss = 0.272356
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 26: Loss = 0.270959
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 27: Loss = 0.269646
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 28: Loss = 0.268047
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 29: Loss = 0.266581
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 30: Loss = 0.265170
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 31: Loss = 0.263509
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 32: Loss = 0.262171
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 33: Loss = 0.260414
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 34: Loss = 0.259005
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 35: Loss = 0.257272
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 36: Loss = 0.255461
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 37: Loss = 0.254026
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 38: Loss = 0.252214
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 39: Loss = 0.250333
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 40: Loss = 0.248623
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 41: Loss = 0.246914
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 42: Loss = 0.244782
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 43: Loss = 0.242670
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 44: Loss = 0.240837
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 45: Loss = 0.238801
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 46: Loss = 0.236289
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 47: Loss = 0.234286
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 48: Loss = 0.232001
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 49: Loss = 0.229588
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 50: Loss = 0.227488
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 51: Loss = 0.224810
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 52: Loss = 0.222215
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 53: Loss = 0.219843
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 54: Loss = 0.217429
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 55: Loss = 0.214421
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 56: Loss = 0.211986
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 57: Loss = 0.208798
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 58: Loss = 0.205968
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 59: Loss = 0.203132
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 60: Loss = 0.200167
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 61: Loss = 0.197347
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 62: Loss = 0.193918
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 63: Loss = 0.191041
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 64: Loss = 0.188011
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 65: Loss = 0.184355
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 66: Loss = 0.181102
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 67: Loss = 0.177826
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 68: Loss = 0.174870
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 69: Loss = 0.171334
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 70: Loss = 0.168304
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 71: Loss = 0.165067
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 72: Loss = 0.161692
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 73: Loss = 0.158342
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 74: Loss = 0.155088
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 75: Loss = 0.151738
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 76: Loss = 0.148052
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 77: Loss = 0.144923
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
  Batch 78: Loss = 0.141887
Batch shape: torch.Size([1, 10000, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10000, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10000, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10000, 128])
  x_emb shape after encoder and view: torch.Size([1, 10000, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10000, 128])
  x_masked shape: torch.Size([1, 7000, 128])
  ids_keep shape: torch.Size([1, 7000])
  ids_mask shape: torch.Size([1, 3000])
  ids_restore shape: torch.Size([1, 10000])
  encoded shape after transformer: torch.Size([1, 7000, 128])
  decoder_input shape: torch.Size([1, 10000, 128])
  linear_decoded shape: torch.Size([1, 10000, 10816])
  conv_input shape: torch.Size([10000, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10000, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10000, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10000, 50, 50, 2])
Traceback (most recent call last):
  File "/media/cc/2T/liouvilleViT/train_masked_blocks.py", line 178, in <module>
    run_training()
  File "/media/cc/2T/liouvilleViT/train_masked_blocks.py", line 140, in run_training
    scaler.step(optimizer)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/amp/grad_scaler.py", line 457, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/amp/grad_scaler.py", line 352, in _maybe_opt_step
    retval = optimizer.step(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    adamw(
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/adamw.py", line 782, in adamw
    func(
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/adamw.py", line 520, in _multi_tensor_adamw
    torch._foreach_add_(
KeyboardInterrupt
