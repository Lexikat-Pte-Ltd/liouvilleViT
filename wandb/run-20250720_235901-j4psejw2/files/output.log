/media/cc/2T/liouvilleViT/train_masked_blocks.py:121: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()  # Initialize GradScaler for mixed precision

--- Epoch 1/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
/media/cc/2T/liouvilleViT/train_masked_blocks.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.285917
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.285364
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.284876
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.281714
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.283714
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.283919
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.277274
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.275595
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.276611
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.275224
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.271022
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.275251
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.270379
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.271357
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.266787
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.270497
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.265599
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.267050
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.263611
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.259197
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.264365
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.267732
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.260467
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.290463
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.253325
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.255545
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.250666
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.249615
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.248205
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.250354
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.247125
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.242345
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.244294
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.238552
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.234777
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.234277
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.236318
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.228587
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.229237
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.228108
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.221805
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.227677
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.219191
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.214776
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.219225
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.225363
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.211563
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.206941
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.203903
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.217507
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.199551
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.202624
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.192251
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.188452
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.188229
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.184997
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.178928
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.179632
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.174414
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.169084
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.168415
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.163633
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.165359
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.155902
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.163660
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.153048
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.155347
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.149713
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.140908
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.138597
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.134264
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.131378
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.128333
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.130779
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.123180
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.120089
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.117080
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.113418
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.112385
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.112918
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.107791
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.106772
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.106213
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.101999
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.101801
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.099496
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.099697
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.100259
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.094121
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.095176
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.094264
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.093928
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.094377
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.092406
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.092776
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.091745
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.094615
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.093053
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.091490
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.090182
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 102: Loss = 0.101737
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 103: Loss = 0.091368
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 104: Loss = 0.093239
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 105: Loss = 0.091644
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 106: Loss = 0.093603
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 107: Loss = 0.092630
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 108: Loss = 0.103983
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 109: Loss = 0.090224
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 110: Loss = 0.090503
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 111: Loss = 0.099490
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 112: Loss = 0.091829
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 113: Loss = 0.094834
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 114: Loss = 0.091739
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 115: Loss = 0.094537
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 116: Loss = 0.089463
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 117: Loss = 0.093351
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 118: Loss = 0.096153
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 119: Loss = 0.096534
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 120: Loss = 0.088283
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 121: Loss = 0.096068
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 122: Loss = 0.090128
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 123: Loss = 0.088931
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 124: Loss = 0.091783
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 125: Loss = 0.091993
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 126: Loss = 0.089833
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 127: Loss = 0.091671
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 128: Loss = 0.089897
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 129: Loss = 0.089855
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 130: Loss = 0.089569
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 131: Loss = 0.089076
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 132: Loss = 0.088731
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 133: Loss = 0.088796
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 134: Loss = 0.088024
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 135: Loss = 0.089332
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 136: Loss = 0.092794
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 137: Loss = 0.090295
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 138: Loss = 0.090888
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 139: Loss = 0.089184
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 140: Loss = 0.088561
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 141: Loss = 0.089522
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 142: Loss = 0.090531
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 143: Loss = 0.087841
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 144: Loss = 0.090815
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 145: Loss = 0.093196
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 146: Loss = 0.090362
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 147: Loss = 0.091332
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 148: Loss = 0.089170
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 149: Loss = 0.087479
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 150: Loss = 0.088455
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 151: Loss = 0.093673
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 152: Loss = 0.096110
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 153: Loss = 0.087637
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 154: Loss = 0.091520
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 155: Loss = 0.091668
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 156: Loss = 0.088837
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 157: Loss = 0.092224
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 158: Loss = 0.089689
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 159: Loss = 0.089220
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 160: Loss = 0.092265
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 161: Loss = 0.095785
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 162: Loss = 0.087723
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 163: Loss = 0.088949
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 164: Loss = 0.089166
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 165: Loss = 0.091168
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 166: Loss = 0.091757
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 167: Loss = 0.088535
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 168: Loss = 0.089632
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 169: Loss = 0.090849
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 170: Loss = 0.096392
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 171: Loss = 0.090496
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 172: Loss = 0.090321
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 173: Loss = 0.087298
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 174: Loss = 0.087313
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 175: Loss = 0.091526
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 176: Loss = 0.089642
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 177: Loss = 0.088764
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 178: Loss = 0.091453
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 179: Loss = 0.088213
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 180: Loss = 0.088164
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 181: Loss = 0.089856
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 182: Loss = 0.098042
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 183: Loss = 0.089400
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 184: Loss = 0.090287
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 185: Loss = 0.091404
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 186: Loss = 0.094965
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 187: Loss = 0.091404
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 188: Loss = 0.091364
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 189: Loss = 0.098654
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 190: Loss = 0.090169
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 191: Loss = 0.089498
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 192: Loss = 0.091047
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 193: Loss = 0.088227
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 194: Loss = 0.092566
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 195: Loss = 0.095916
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 196: Loss = 0.089683
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 197: Loss = 0.088589
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 198: Loss = 0.088548
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 199: Loss = 0.092326
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 200: Loss = 0.101581
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 201: Loss = 0.089944
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 202: Loss = 0.092468
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 203: Loss = 0.088061
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 204: Loss = 0.089158
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 205: Loss = 0.087190
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 206: Loss = 0.087718
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 207: Loss = 0.088906
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 208: Loss = 0.089927
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 209: Loss = 0.089118
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 210: Loss = 0.087627
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 211: Loss = 0.087941
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 212: Loss = 0.088724
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 213: Loss = 0.093321
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 214: Loss = 0.089382
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 215: Loss = 0.088575
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 216: Loss = 0.090676
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 217: Loss = 0.091754
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 218: Loss = 0.088630
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 219: Loss = 0.090346
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 220: Loss = 0.090505
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 221: Loss = 0.088923
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 222: Loss = 0.094184
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 223: Loss = 0.087431
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 224: Loss = 0.089693
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 225: Loss = 0.088710
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 226: Loss = 0.088984
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 227: Loss = 0.090727
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 228: Loss = 0.089408
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 229: Loss = 0.088159
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 230: Loss = 0.089261
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 231: Loss = 0.087366
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 232: Loss = 0.088536
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 233: Loss = 0.087561
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 234: Loss = 0.086902
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 235: Loss = 0.090797
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 236: Loss = 0.085875
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 237: Loss = 0.089454
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 238: Loss = 0.086210
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 239: Loss = 0.087329
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 240: Loss = 0.088163
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 241: Loss = 0.097665
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 242: Loss = 0.093887
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 243: Loss = 0.087191
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 244: Loss = 0.095395
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 245: Loss = 0.089123
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 246: Loss = 0.087180
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 247: Loss = 0.101527
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 248: Loss = 0.089643
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 249: Loss = 0.089307
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 250: Loss = 0.091150
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 251: Loss = 0.089367
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 252: Loss = 0.095491
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 253: Loss = 0.089535
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 254: Loss = 0.091341
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 255: Loss = 0.086601
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 256: Loss = 0.088629
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 257: Loss = 0.089978
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 258: Loss = 0.086677
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 259: Loss = 0.089877
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 260: Loss = 0.089703
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 261: Loss = 0.090093
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 262: Loss = 0.088451
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 263: Loss = 0.090194
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 264: Loss = 0.087808
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 265: Loss = 0.095215
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 266: Loss = 0.087982
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 267: Loss = 0.091650
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 268: Loss = 0.089161
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 269: Loss = 0.087576
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 270: Loss = 0.088209
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 271: Loss = 0.089319
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 272: Loss = 0.086396
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 273: Loss = 0.089344
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 274: Loss = 0.088222
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 275: Loss = 0.089553
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 276: Loss = 0.088858
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 277: Loss = 0.095072
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 278: Loss = 0.089576
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 279: Loss = 0.093217
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 280: Loss = 0.090756
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 281: Loss = 0.087542
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 282: Loss = 0.089097
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 283: Loss = 0.090066
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 284: Loss = 0.088828
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 285: Loss = 0.088326
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 286: Loss = 0.086876
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 287: Loss = 0.088341
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 288: Loss = 0.098140
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 289: Loss = 0.090425
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 290: Loss = 0.089193
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 291: Loss = 0.089715
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 292: Loss = 0.090406
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 293: Loss = 0.086361
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 294: Loss = 0.090882
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 295: Loss = 0.091485
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 296: Loss = 0.090073
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 297: Loss = 0.088634
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 298: Loss = 0.098737
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 299: Loss = 0.089718
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 300: Loss = 0.088230
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 301: Loss = 0.089709
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 302: Loss = 0.093538
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 303: Loss = 0.088840
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 304: Loss = 0.091279
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 305: Loss = 0.089136
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 306: Loss = 0.091762
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 307: Loss = 0.088148
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 308: Loss = 0.086961
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 309: Loss = 0.093449
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 310: Loss = 0.090503
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 311: Loss = 0.092341
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 312: Loss = 0.087656
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 313: Loss = 0.086836
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 314: Loss = 0.089658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 315: Loss = 0.094379
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 316: Loss = 0.094384
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 317: Loss = 0.088061
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 318: Loss = 0.088613
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 319: Loss = 0.086983
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 320: Loss = 0.088260
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 321: Loss = 0.089598
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 322: Loss = 0.090117
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 323: Loss = 0.085245
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 324: Loss = 0.089161
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 325: Loss = 0.087445
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 326: Loss = 0.086836
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 327: Loss = 0.090148
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 328: Loss = 0.091235
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 329: Loss = 0.088107
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 330: Loss = 0.088061
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 331: Loss = 0.089002
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 332: Loss = 0.094799
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 333: Loss = 0.088256
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 334: Loss = 0.087062
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 335: Loss = 0.089150
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 336: Loss = 0.088417
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 337: Loss = 0.088400
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 338: Loss = 0.094525
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 339: Loss = 0.088355
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 340: Loss = 0.088781
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 341: Loss = 0.092037
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 342: Loss = 0.087907
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 343: Loss = 0.087859
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 344: Loss = 0.088481
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 345: Loss = 0.091872
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 346: Loss = 0.088765
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 347: Loss = 0.088779
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 348: Loss = 0.089132
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 349: Loss = 0.088067
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 350: Loss = 0.087192
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 351: Loss = 0.086662
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 352: Loss = 0.088140
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 353: Loss = 0.089753
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 354: Loss = 0.088155
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 355: Loss = 0.089324
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 356: Loss = 0.087275
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 357: Loss = 0.088022
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 358: Loss = 0.088686
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 359: Loss = 0.093879
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 360: Loss = 0.087652
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 361: Loss = 0.088106
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 362: Loss = 0.088360
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 363: Loss = 0.090412
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 364: Loss = 0.088885
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 365: Loss = 0.090147
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 366: Loss = 0.088287
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 367: Loss = 0.087701
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 368: Loss = 0.090311
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 369: Loss = 0.086708
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 370: Loss = 0.088800
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 371: Loss = 0.090324
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 372: Loss = 0.089357
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 373: Loss = 0.087446
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 374: Loss = 0.094217
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 375: Loss = 0.089222
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 376: Loss = 0.087708
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 377: Loss = 0.089730
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 378: Loss = 0.088685
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 379: Loss = 0.097742
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 380: Loss = 0.090620
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 381: Loss = 0.089269
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 382: Loss = 0.088528
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 383: Loss = 0.085347
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 384: Loss = 0.086775
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 385: Loss = 0.087766
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 386: Loss = 0.087785
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 387: Loss = 0.087075
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 388: Loss = 0.091086
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 389: Loss = 0.087791
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 390: Loss = 0.095172
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 391: Loss = 0.086931
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 392: Loss = 0.089495
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 393: Loss = 0.089712
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 394: Loss = 0.094741
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 395: Loss = 0.090387
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 396: Loss = 0.084143
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 397: Loss = 0.089874
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 398: Loss = 0.092942
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 399: Loss = 0.088282
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 400: Loss = 0.088668
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 401: Loss = 0.092451
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 402: Loss = 0.088369
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 403: Loss = 0.087225
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 404: Loss = 0.085841
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 405: Loss = 0.091279
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 406: Loss = 0.090323
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 407: Loss = 0.095946
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 408: Loss = 0.091890
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 409: Loss = 0.089487
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 410: Loss = 0.090072
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 411: Loss = 0.094694
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 412: Loss = 0.087699
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 413: Loss = 0.089855
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 414: Loss = 0.089365
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 415: Loss = 0.088564
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 416: Loss = 0.093686
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 417: Loss = 0.092758
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 418: Loss = 0.086944
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 419: Loss = 0.087591
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 420: Loss = 0.088981
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 421: Loss = 0.086876
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 422: Loss = 0.088534
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 423: Loss = 0.088946
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 424: Loss = 0.092663
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 425: Loss = 0.091904
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 426: Loss = 0.087344
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 427: Loss = 0.092942
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 428: Loss = 0.087411
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 429: Loss = 0.088977
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 430: Loss = 0.089749
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 431: Loss = 0.088397
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 432: Loss = 0.092209
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 433: Loss = 0.087582
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 434: Loss = 0.091282
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 435: Loss = 0.088375
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 436: Loss = 0.094053
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 437: Loss = 0.089751
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 438: Loss = 0.088866
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 439: Loss = 0.095144
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 440: Loss = 0.093581
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 441: Loss = 0.089258
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 442: Loss = 0.089416
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 443: Loss = 0.086224
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 444: Loss = 0.089490
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 445: Loss = 0.088782
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 446: Loss = 0.088428
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 447: Loss = 0.086151
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 448: Loss = 0.089634
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 449: Loss = 0.088165
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 450: Loss = 0.092821
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 451: Loss = 0.090324
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 452: Loss = 0.090263
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 453: Loss = 0.088151
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 454: Loss = 0.088632
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 455: Loss = 0.085414
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 456: Loss = 0.089929
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 457: Loss = 0.091682
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 458: Loss = 0.088126
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 459: Loss = 0.087111
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 460: Loss = 0.089083
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 461: Loss = 0.088407
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 462: Loss = 0.093557
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 463: Loss = 0.087452
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 464: Loss = 0.087273
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 465: Loss = 0.086305
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 466: Loss = 0.088386
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 467: Loss = 0.088059
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 468: Loss = 0.089873
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 469: Loss = 0.087786
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 470: Loss = 0.086293
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 471: Loss = 0.095420
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 472: Loss = 0.088298
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 473: Loss = 0.088254
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 474: Loss = 0.088408
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 475: Loss = 0.089049
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 476: Loss = 0.086744
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 477: Loss = 0.086585
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 478: Loss = 0.088938
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 479: Loss = 0.089358
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 480: Loss = 0.088238
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 481: Loss = 0.088319
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 482: Loss = 0.088774
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 483: Loss = 0.088988
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 484: Loss = 0.087718
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 485: Loss = 0.088044
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 486: Loss = 0.088424
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 487: Loss = 0.090025
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 488: Loss = 0.089743
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 489: Loss = 0.087466
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 490: Loss = 0.088006
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 491: Loss = 0.088589
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 492: Loss = 0.088785
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 493: Loss = 0.087288
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 494: Loss = 0.087478
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 495: Loss = 0.089291
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 496: Loss = 0.086372
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 497: Loss = 0.088494
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 498: Loss = 0.088243
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 499: Loss = 0.088028
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 500: Loss = 0.090370
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 501: Loss = 0.087418
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 502: Loss = 0.090872
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 503: Loss = 0.086748
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 504: Loss = 0.089562
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 505: Loss = 0.087041
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 506: Loss = 0.085639
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 507: Loss = 0.086740
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 508: Loss = 0.088112
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 509: Loss = 0.088608
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 510: Loss = 0.087347
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 511: Loss = 0.089989
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 512: Loss = 0.087837
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 513: Loss = 0.087705
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 514: Loss = 0.089154
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 515: Loss = 0.091641
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 516: Loss = 0.088226
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 517: Loss = 0.088755
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 518: Loss = 0.087840
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 519: Loss = 0.092047
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 520: Loss = 0.089333
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 521: Loss = 0.094519
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 522: Loss = 0.089089
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 523: Loss = 0.088611
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 524: Loss = 0.089687
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 525: Loss = 0.085980
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 526: Loss = 0.091303
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 527: Loss = 0.088090
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 528: Loss = 0.090225
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 529: Loss = 0.088332
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 530: Loss = 0.089288
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 531: Loss = 0.086740
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 532: Loss = 0.087941
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 533: Loss = 0.090014
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 534: Loss = 0.086428
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 535: Loss = 0.089205
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 536: Loss = 0.087508
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 537: Loss = 0.088199
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 538: Loss = 0.090495
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 539: Loss = 0.088707
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 540: Loss = 0.088162
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 541: Loss = 0.094489
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 542: Loss = 0.090818
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 543: Loss = 0.087461
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 544: Loss = 0.087630
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 545: Loss = 0.097724
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 546: Loss = 0.087084
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 547: Loss = 0.088423
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 548: Loss = 0.088461
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 549: Loss = 0.085960
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 550: Loss = 0.087802
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 551: Loss = 0.088231
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 552: Loss = 0.087955
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 553: Loss = 0.089333
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 554: Loss = 0.086200
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 555: Loss = 0.087293
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 556: Loss = 0.089407
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 557: Loss = 0.086730
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 558: Loss = 0.094352
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 559: Loss = 0.091157
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 560: Loss = 0.086216
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 561: Loss = 0.095347
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 562: Loss = 0.085984
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 563: Loss = 0.087595
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 564: Loss = 0.088479
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 565: Loss = 0.086559
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 566: Loss = 0.090463
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 567: Loss = 0.088444
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 568: Loss = 0.087724
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 569: Loss = 0.094519
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 570: Loss = 0.088306
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 571: Loss = 0.088527
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 572: Loss = 0.088663
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 573: Loss = 0.089669
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 574: Loss = 0.094988
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 575: Loss = 0.087924
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 576: Loss = 0.088173
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 577: Loss = 0.088920
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 578: Loss = 0.089058
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 579: Loss = 0.088922
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 580: Loss = 0.091199
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 581: Loss = 0.086286
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 582: Loss = 0.089262
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 583: Loss = 0.087074
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 584: Loss = 0.090920
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 585: Loss = 0.087913
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 586: Loss = 0.090349
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 587: Loss = 0.087915
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 588: Loss = 0.088641
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 589: Loss = 0.087693
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 590: Loss = 0.089322
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 591: Loss = 0.087289
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 592: Loss = 0.087967
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 593: Loss = 0.086646
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 594: Loss = 0.088524
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 595: Loss = 0.096975
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 596: Loss = 0.088638
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 597: Loss = 0.086866
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 598: Loss = 0.087870
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 599: Loss = 0.088574
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 600: Loss = 0.087641
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 601: Loss = 0.087841
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 602: Loss = 0.088031
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 603: Loss = 0.089232
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 604: Loss = 0.085085
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 605: Loss = 0.088668
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 606: Loss = 0.087598
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 607: Loss = 0.089555
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 608: Loss = 0.089098
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 609: Loss = 0.086806
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 610: Loss = 0.086732
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 611: Loss = 0.088299
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 612: Loss = 0.091333
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 613: Loss = 0.086555
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 614: Loss = 0.086078
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 615: Loss = 0.093403
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 616: Loss = 0.089876
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 617: Loss = 0.087423
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 618: Loss = 0.087107
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 619: Loss = 0.088356
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 620: Loss = 0.096626
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 621: Loss = 0.084341
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 622: Loss = 0.087221
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 623: Loss = 0.090302
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 624: Loss = 0.090205
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 625: Loss = 0.086664
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 626: Loss = 0.090279
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 627: Loss = 0.088684
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 628: Loss = 0.087062
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 629: Loss = 0.088725
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 630: Loss = 0.086912
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 631: Loss = 0.089661
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 632: Loss = 0.087724
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 633: Loss = 0.086613
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 634: Loss = 0.086883
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 635: Loss = 0.089422
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 636: Loss = 0.089318
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 637: Loss = 0.086973
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 638: Loss = 0.088493
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 639: Loss = 0.085977
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 640: Loss = 0.088317
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 641: Loss = 0.088277
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 642: Loss = 0.090273
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 643: Loss = 0.087336
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 644: Loss = 0.088318
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 645: Loss = 0.088349
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 646: Loss = 0.087937
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 647: Loss = 0.090017
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 648: Loss = 0.088653
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 649: Loss = 0.088243
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 650: Loss = 0.085859
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 651: Loss = 0.088915
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 652: Loss = 0.090860
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 653: Loss = 0.091133
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 654: Loss = 0.086876
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 655: Loss = 0.094196
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 656: Loss = 0.087011
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 657: Loss = 0.086748
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 658: Loss = 0.089602
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 659: Loss = 0.087543
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 660: Loss = 0.089513
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 661: Loss = 0.087840
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 662: Loss = 0.088930
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 663: Loss = 0.086997
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 664: Loss = 0.087003
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 665: Loss = 0.089123
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 666: Loss = 0.086823
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 667: Loss = 0.087408
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 668: Loss = 0.087679
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 669: Loss = 0.088671
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 670: Loss = 0.088990
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 671: Loss = 0.089233
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 672: Loss = 0.086711
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 673: Loss = 0.089408
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 674: Loss = 0.086823
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 675: Loss = 0.087330
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 676: Loss = 0.089095
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 677: Loss = 0.087334
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 678: Loss = 0.086512
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 679: Loss = 0.091102
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 680: Loss = 0.085709
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 681: Loss = 0.087517
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 682: Loss = 0.087722
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 683: Loss = 0.088249
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 684: Loss = 0.089042
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 685: Loss = 0.086407
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 686: Loss = 0.096961
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 687: Loss = 0.090160
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 688: Loss = 0.087750
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 689: Loss = 0.088569
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 690: Loss = 0.087553
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 691: Loss = 0.086594
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 692: Loss = 0.088368
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 693: Loss = 0.089716
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 694: Loss = 0.090226
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 695: Loss = 0.090511
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 696: Loss = 0.089400
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 697: Loss = 0.088867
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 698: Loss = 0.088395
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 699: Loss = 0.087456
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 700: Loss = 0.088883
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 701: Loss = 0.088220
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 702: Loss = 0.087902
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 703: Loss = 0.088640
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 704: Loss = 0.088756
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 705: Loss = 0.086689
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 706: Loss = 0.095727
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 707: Loss = 0.089115
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 708: Loss = 0.087566
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 709: Loss = 0.091088
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 710: Loss = 0.088038
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 711: Loss = 0.086623
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 712: Loss = 0.089240
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 713: Loss = 0.087969
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 714: Loss = 0.087931
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 715: Loss = 0.088410
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 716: Loss = 0.091724
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 717: Loss = 0.087284
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 718: Loss = 0.086386
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 719: Loss = 0.090699
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 720: Loss = 0.086654
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 721: Loss = 0.088036
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 722: Loss = 0.086538
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 723: Loss = 0.087202
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 724: Loss = 0.086695
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 725: Loss = 0.086383
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 726: Loss = 0.086526
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 727: Loss = 0.088881
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 728: Loss = 0.086826
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 729: Loss = 0.087930
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 730: Loss = 0.087910
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 731: Loss = 0.090509
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 732: Loss = 0.086845
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 733: Loss = 0.089225
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 734: Loss = 0.089192
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 735: Loss = 0.093643
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 736: Loss = 0.088655
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 737: Loss = 0.093713
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 738: Loss = 0.088407
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 739: Loss = 0.092612
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 740: Loss = 0.090652
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 741: Loss = 0.085481
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 742: Loss = 0.085157
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 743: Loss = 0.088315
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 744: Loss = 0.089226
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 745: Loss = 0.086697
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 746: Loss = 0.085402
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 747: Loss = 0.087896
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 748: Loss = 0.090067
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 749: Loss = 0.088715
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 750: Loss = 0.090061
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 751: Loss = 0.094635
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 752: Loss = 0.086782
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 753: Loss = 0.086434
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 754: Loss = 0.087683
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 755: Loss = 0.087351
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 756: Loss = 0.089488
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 757: Loss = 0.088641
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
Traceback (most recent call last):
  File "/media/cc/2T/liouvilleViT/train_masked_blocks.py", line 183, in <module>
    run_training()
  File "/media/cc/2T/liouvilleViT/train_masked_blocks.py", line 133, in run_training
    pred, ids_mask = model(batch)  # pred: [1, num_blocks, 50, 50, 2]
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/cc/2T/liouvilleViT/masked_block_vit.py", line 98, in forward
    encoded = self.transformer(x_masked)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 511, in forward
    output = mod(
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 904, in forward
    + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 918, in _sa_block
    x = self.self_attn(
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1368, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/functional.py", line 6285, in multi_head_attention_forward
    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
KeyboardInterrupt
